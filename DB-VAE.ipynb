{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part2_Debiasing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ag_e7xtTzT1W",
        "QOpPUH3FR179",
        "NDj7KBaW8Asz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNbf1pRlSDby"
      },
      "source": [
        "# Copyright 2022 MIT 6.S191 Introduction to Deep Learning. All Rights Reserved.\n",
        "# \n",
        "# Licensed under the MIT License. You may not use this file except in compliance\n",
        "# with the License. Use and/or modification of this code outside of 6.S191 must\n",
        "# reference:\n",
        "#\n",
        "# Â© MIT 6.S191: Introduction to Deep Learning\n",
        "# http://introtodeeplearning.com\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E46sWVKK6LP9"
      },
      "source": [
        "# Import Tensorflow 2.0\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import IPython\n",
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Download and import the MIT 6.S191 package\n",
        "!pip install mitdeeplearning\n",
        "import mitdeeplearning as mdl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWXaaIWy6jVw"
      },
      "source": [
        "# Get the training data: both images from CelebA and ImageNet\n",
        "path_to_training_data = tf.keras.utils.get_file('train_face.h5', 'https://www.dropbox.com/s/hlz8atheyozp1yx/train_face.h5?dl=1')\n",
        "# Instantiate a TrainingDatasetLoader using the downloaded dataset\n",
        "loader = mdl.lab2.TrainingDatasetLoader(path_to_training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIE321rxa_b3"
      },
      "source": [
        "We can look at the size of the training dataset and grab a batch of size 100:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82EVTAAW7B_X"
      },
      "source": [
        "### Define the CNN model ###\n",
        "\n",
        "n_filters = 12 # base number of convolutional filters\n",
        "\n",
        "'''Function to define a standard CNN model'''\n",
        "def make_standard_classifier(n_outputs=1):\n",
        "  Conv2D = functools.partial(tf.keras.layers.Conv2D, padding='same', activation='relu')\n",
        "  BatchNormalization = tf.keras.layers.BatchNormalization\n",
        "  Flatten = tf.keras.layers.Flatten\n",
        "  Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    Conv2D(filters=1*n_filters, kernel_size=5,  strides=2),\n",
        "    BatchNormalization(),\n",
        "    \n",
        "    Conv2D(filters=2*n_filters, kernel_size=5,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=4*n_filters, kernel_size=3,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=6*n_filters, kernel_size=3,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512),\n",
        "    Dense(n_outputs, activation=None),\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "standard_classifier = make_standard_classifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-eWf3l_lCri"
      },
      "source": [
        "Now let's train the standard CNN!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJlDGh1o31G1"
      },
      "source": [
        "### Train the standard CNN ###\n",
        "\n",
        "# Training hyperparameters\n",
        "batch_size = 32\n",
        "num_epochs = 2  # keep small to run faster\n",
        "learning_rate = 5e-4\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate) # define our optimizer\n",
        "loss_history = mdl.util.LossHistory(smoothing_factor=0.99) # to record loss evolution\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, scale='semilogy')\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "\n",
        "@tf.function\n",
        "def standard_train_step(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # feed the images into the model\n",
        "    logits = standard_classifier(x) \n",
        "    # Compute the loss\n",
        "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "\n",
        "  # Backpropagation\n",
        "  grads = tape.gradient(loss, standard_classifier.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, standard_classifier.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "# The training loop!\n",
        "for epoch in range(num_epochs):\n",
        "  for idx in tqdm(range(loader.get_train_size()//batch_size)):\n",
        "    # Grab a batch of training data and propagate through the network\n",
        "    x, y = loader.get_batch(batch_size)\n",
        "    loss = standard_train_step(x, y)\n",
        "\n",
        "    # Record the loss and plot the evolution of the loss as a function of training\n",
        "    loss_history.append(loss.numpy().mean())\n",
        "    plotter.plot(loss_history.get())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKMdWVHeCxj8"
      },
      "source": [
        "### Evaluate performance of the standard CNN\n",
        "\n",
        "Next, let's evaluate the classification performance of our CelebA-trained standard CNN on the training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35-PDgjdWk6_"
      },
      "source": [
        "### Evaluation of standard CNN ###\n",
        "\n",
        "# TRAINING DATA\n",
        "# Evaluate on a subset of CelebA+Imagenet\n",
        "(batch_x, batch_y) = loader.get_batch(5000)\n",
        "y_pred_standard = tf.round(tf.nn.sigmoid(standard_classifier.predict(batch_x)))\n",
        "acc_standard = tf.reduce_mean(tf.cast(tf.equal(batch_y, y_pred_standard), tf.float32))\n",
        "\n",
        "print(\"Standard CNN accuracy on (potentially biased) training set: {:.4f}\".format(acc_standard.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfDD8ztGWk6x"
      },
      "source": [
        "### Load test dataset and plot examples ###\n",
        "\n",
        "test_faces = mdl.lab2.get_test_faces()\n",
        "keys = [\"Light Female\", \"Light Male\", \"Dark Female\", \"Dark Male\"]\n",
        "for group, key in zip(test_faces,keys): \n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(np.hstack(group))\n",
        "  plt.title(key, fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo1z3cdbEUMM"
      },
      "source": [
        "Now, let's evaluated the probability of each of these face demographics being classified as a face using the standard CNN classifier we've just trained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI4O0Y1GAot9"
      },
      "source": [
        "### Evaluate the standard CNN on the test data ### \n",
        "\n",
        "standard_classifier_logits = [standard_classifier(np.array(x, dtype=np.float32)) for x in test_faces]\n",
        "standard_classifier_probs = tf.squeeze(tf.sigmoid(standard_classifier_logits))\n",
        "\n",
        "# Plot the prediction accuracies per demographic\n",
        "xx = range(len(keys))\n",
        "yy = standard_classifier_probs.numpy().mean(1)\n",
        "plt.bar(xx, yy)\n",
        "plt.xticks(xx, keys)\n",
        "plt.ylim(max(0,yy.min()-yy.ptp()/2.), yy.max()+yy.ptp()/2.)\n",
        "plt.title(\"Standard classifier predictions\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S00ASo1ImSuh"
      },
      "source": [
        "### Defining the VAE loss function ###\n",
        "\n",
        "''' Function to calculate VAE loss given:\n",
        "      an input x, \n",
        "      reconstructed output x_recon, \n",
        "      encoded means mu, \n",
        "      encoded log of standard deviation logsigma, \n",
        "      weight parameter for the latent loss kl_weight\n",
        "'''\n",
        "def vae_loss_function(x, x_recon, mu, logsigma, kl_weight=0.0005):\n",
        "  # TODO: Define the latent loss. Note this is given in the equation for L_{KL}\n",
        "  # in the text block directly above\n",
        "  latent_loss = # TODO\n",
        "\n",
        "  # TODO: Define the reconstruction loss as the mean absolute pixel-wise \n",
        "  # difference between the input and reconstruction. Hint: you'll need to \n",
        "  # use tf.reduce_mean, and supply an axis argument which specifies which \n",
        "  # dimensions to reduce over. For example, reconstruction loss needs to average \n",
        "  # over the height, width, and channel image dimensions.\n",
        "  # https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean\n",
        "  reconstruction_loss = # TODO\n",
        "\n",
        "  # TODO: Define the VAE loss. Note this is given in the equation for L_{VAE}\n",
        "  # in the text block directly above\n",
        "  vae_loss = # TODO\n",
        "  \n",
        "  return vae_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT6PGdNajl3K"
      },
      "source": [
        "### VAE Reparameterization ###\n",
        "\n",
        "\"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
        "# Arguments\n",
        "    z_mean, z_logsigma (tensor): mean and log of standard deviation of latent distribution (Q(z|X))\n",
        "# Returns\n",
        "    z (tensor): sampled latent vector\n",
        "\"\"\"\n",
        "def sampling(z_mean, z_logsigma):\n",
        "  # By default, random.normal is \"standard\" (ie. mean=0 and std=1.0)\n",
        "  batch, latent_dim = z_mean.shape\n",
        "  epsilon = tf.random.normal(shape=(batch, latent_dim))\n",
        "\n",
        "  # TODO: Define the reparameterization computation!\n",
        "  # Note the equation is given in the text block immediately above.\n",
        "  z = # TODO\n",
        "  return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjieDs8Ovcqs"
      },
      "source": [
        "### Loss function for DB-VAE ###\n",
        "\n",
        "\"\"\"Loss function for DB-VAE.\n",
        "# Arguments\n",
        "    x: true input x\n",
        "    x_pred: reconstructed x\n",
        "    y: true label (face or not face)\n",
        "    y_logit: predicted labels\n",
        "    mu: mean of latent distribution (Q(z|X))\n",
        "    logsigma: log of standard deviation of latent distribution (Q(z|X))\n",
        "# Returns\n",
        "    total_loss: DB-VAE total loss\n",
        "    classification_loss = DB-VAE classification loss\n",
        "\"\"\"\n",
        "def debiasing_loss_function(x, x_pred, y, y_logit, mu, logsigma):\n",
        "\n",
        "  # TODO: call the relevant function to obtain VAE loss\n",
        "  vae_loss = vae_loss_function('''TODO''') # TODO\n",
        "\n",
        "  # TODO: define the classification loss using sigmoid_cross_entropy\n",
        "  # https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
        "  classification_loss = # TODO\n",
        "\n",
        "  # Use the training data labels to create variable face_indicator:\n",
        "  #   indicator that reflects which training data are images of faces\n",
        "  face_indicator = tf.cast(tf.equal(y, 1), tf.float32)\n",
        "\n",
        "  # TODO: define the DB-VAE total loss! Use tf.reduce_mean to average over all\n",
        "  # samples\n",
        "  total_loss = # TODO\n",
        "\n",
        "  return total_loss, classification_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfWPHGrmyE7R"
      },
      "source": [
        "### Define the decoder portion of the DB-VAE ###\n",
        "\n",
        "n_filters = 12 # base number of convolutional filters, same as standard CNN\n",
        "latent_dim = 100 # number of latent variables\n",
        "\n",
        "def make_face_decoder_network():\n",
        "  # Functionally define the different layer types we will use\n",
        "  Conv2DTranspose = functools.partial(tf.keras.layers.Conv2DTranspose, padding='same', activation='relu')\n",
        "  BatchNormalization = tf.keras.layers.BatchNormalization\n",
        "  Flatten = tf.keras.layers.Flatten\n",
        "  Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
        "  Reshape = tf.keras.layers.Reshape\n",
        "\n",
        "  # Build the decoder network using the Sequential API\n",
        "  decoder = tf.keras.Sequential([\n",
        "    # Transform to pre-convolutional generation\n",
        "    Dense(units=4*4*6*n_filters),  # 4x4 feature maps (with 6N occurances)\n",
        "    Reshape(target_shape=(4, 4, 6*n_filters)),\n",
        "\n",
        "    # Upscaling convolutions (inverse of encoder)\n",
        "    Conv2DTranspose(filters=4*n_filters, kernel_size=3,  strides=2),\n",
        "    Conv2DTranspose(filters=2*n_filters, kernel_size=3,  strides=2),\n",
        "    Conv2DTranspose(filters=1*n_filters, kernel_size=5,  strides=2),\n",
        "    Conv2DTranspose(filters=3, kernel_size=5,  strides=2),\n",
        "  ])\n",
        "\n",
        "  return decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSFDcFBL13c3"
      },
      "source": [
        "### Defining and creating the DB-VAE ###\n",
        "\n",
        "class DB_VAE(tf.keras.Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(DB_VAE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "    # Define the number of outputs for the encoder. Recall that we have \n",
        "    # `latent_dim` latent variables, as well as a supervised output for the \n",
        "    # classification.\n",
        "    num_encoder_dims = 2*self.latent_dim + 1\n",
        "\n",
        "    self.encoder = make_standard_classifier(num_encoder_dims)\n",
        "    self.decoder = make_face_decoder_network()\n",
        "\n",
        "  # function to feed images into encoder, encode the latent space, and output\n",
        "  #   classification probability \n",
        "  def encode(self, x):\n",
        "    # encoder output\n",
        "    encoder_output = self.encoder(x)\n",
        "\n",
        "    # classification prediction\n",
        "    y_logit = tf.expand_dims(encoder_output[:, 0], -1)\n",
        "    # latent variable distribution parameters\n",
        "    z_mean = encoder_output[:, 1:self.latent_dim+1] \n",
        "    z_logsigma = encoder_output[:, self.latent_dim+1:]\n",
        "\n",
        "    return y_logit, z_mean, z_logsigma\n",
        "\n",
        "  # VAE reparameterization: given a mean and logsigma, sample latent variables\n",
        "  def reparameterize(self, z_mean, z_logsigma):\n",
        "    # TODO: call the sampling function defined above\n",
        "    z = # TODO\n",
        "    return z\n",
        "\n",
        "  # Decode the latent space and output reconstruction\n",
        "  def decode(self, z):\n",
        "    # TODO: use the decoder to output the reconstruction\n",
        "    reconstruction = # TODO\n",
        "    return reconstruction\n",
        "\n",
        "  # The call function will be used to pass inputs x through the core VAE\n",
        "  def call(self, x): \n",
        "    # Encode input to a prediction and latent space\n",
        "    y_logit, z_mean, z_logsigma = self.encode(x)\n",
        "\n",
        "    # TODO: reparameterization\n",
        "    z = # TODO\n",
        "\n",
        "    # TODO: reconstruction\n",
        "    recon = # TODO\n",
        "    return y_logit, z_mean, z_logsigma, recon\n",
        "\n",
        "  # Predict face or not face logit for given input x\n",
        "  def predict(self, x):\n",
        "    y_logit, z_mean, z_logsigma = self.encode(x)\n",
        "    return y_logit\n",
        "\n",
        "dbvae = DB_VAE(latent_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewWbf7TE7wVc"
      },
      "source": [
        "# Function to return the means for an input image batch\n",
        "def get_latent_mu(images, dbvae, batch_size=1024):\n",
        "  N = images.shape[0]\n",
        "  mu = np.zeros((N, latent_dim))\n",
        "  for start_ind in range(0, N, batch_size):\n",
        "    end_ind = min(start_ind+batch_size, N+1)\n",
        "    batch = (images[start_ind:end_ind]).astype(np.float32)/255.\n",
        "    _, batch_mu, _ = dbvae.encode(batch)\n",
        "    mu[start_ind:end_ind] = batch_mu\n",
        "  return mu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiX9pmmC7_wn"
      },
      "source": [
        "### Resampling algorithm for DB-VAE ###\n",
        "\n",
        "'''Function that recomputes the sampling probabilities for images within a batch\n",
        "      based on how they distribute across the training data'''\n",
        "def get_training_sample_probabilities(images, dbvae, bins=10, smoothing_fac=0.001): \n",
        "    print(\"Recomputing the sampling probabilities\")\n",
        "    \n",
        "    # TODO: run the input batch and get the latent variable means\n",
        "    mu = get_latent_mu('''TODO''') # TODO\n",
        "\n",
        "    # sampling probabilities for the images\n",
        "    training_sample_p = np.zeros(mu.shape[0])\n",
        "    \n",
        "    # consider the distribution for each latent variable \n",
        "    for i in range(latent_dim):\n",
        "      \n",
        "        latent_distribution = mu[:,i]\n",
        "        # generate a histogram of the latent distribution\n",
        "        hist_density, bin_edges =  np.histogram(latent_distribution, density=True, bins=bins)\n",
        "\n",
        "        # find which latent bin every data sample falls in \n",
        "        bin_edges[0] = -float('inf')\n",
        "        bin_edges[-1] = float('inf')\n",
        "        \n",
        "        # TODO: call the digitize function to find which bins in the latent distribution \n",
        "        #    every data sample falls in to\n",
        "        # https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.digitize.html\n",
        "        bin_idx = np.digitize('''TODO''', '''TODO''') # TODO\n",
        "\n",
        "        # smooth the density function\n",
        "        hist_smoothed_density = hist_density + smoothing_fac\n",
        "        hist_smoothed_density = hist_smoothed_density / np.sum(hist_smoothed_density)\n",
        "\n",
        "        # invert the density function \n",
        "        p = 1.0/(hist_smoothed_density[bin_idx-1])\n",
        "        \n",
        "        # TODO: normalize all probabilities\n",
        "        p = # TODO\n",
        "        \n",
        "        # TODO: update sampling probabilities by considering whether the newly\n",
        "        #     computed p is greater than the existing sampling probabilities.\n",
        "        training_sample_p = # TODO\n",
        "        \n",
        "    # final normalization\n",
        "    training_sample_p /= np.sum(training_sample_p)\n",
        "\n",
        "    return training_sample_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwQs-Gu5bKEK"
      },
      "source": [
        "### Training the DB-VAE ###\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "latent_dim = 100\n",
        "\n",
        "# DB-VAE needs slightly more epochs to train since its more complex than \n",
        "# the standard classifier so we use 6 instead of 2\n",
        "num_epochs = 6  \n",
        "\n",
        "# instantiate a new DB-VAE model and optimizer\n",
        "dbvae = DB_VAE(100)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# To define the training operation, we will use tf.function which is a powerful tool \n",
        "#   that lets us turn a Python function into a TensorFlow computation graph.\n",
        "@tf.function\n",
        "def debiasing_train_step(x, y):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Feed input x into dbvae. Note that this is using the DB_VAE call function!\n",
        "    y_logit, z_mean, z_logsigma, x_recon = dbvae(x)\n",
        "\n",
        "    '''TODO: call the DB_VAE loss function to compute the loss'''\n",
        "    loss, class_loss = debiasing_loss_function('''TODO arguments''') # TODO\n",
        "  \n",
        "  '''TODO: use the GradientTape.gradient method to compute the gradients.\n",
        "     Hint: this is with respect to the trainable_variables of the dbvae.'''\n",
        "  grads = tape.gradient('''TODO''', '''TODO''') # TODO\n",
        "\n",
        "  # apply gradients to variables\n",
        "  optimizer.apply_gradients(zip(grads, dbvae.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "# get training faces from data loader\n",
        "all_faces = loader.get_all_train_faces()\n",
        "\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "\n",
        "# The training loop -- outer loop iterates over the number of epochs\n",
        "for i in range(num_epochs):\n",
        "\n",
        "  IPython.display.clear_output(wait=True)\n",
        "  print(\"Starting epoch {}/{}\".format(i+1, num_epochs))\n",
        "\n",
        "  # Recompute data sampling proabilities\n",
        "  '''TODO: recompute the sampling probabilities for debiasing'''\n",
        "  p_faces = get_training_sample_probabilities('''TODO''', '''TODO''') # TODO\n",
        "  \n",
        "  # get a batch of training data and compute the training step\n",
        "  for j in tqdm(range(loader.get_train_size() // batch_size)):\n",
        "    # load a batch of data\n",
        "    (x, y) = loader.get_batch(batch_size, p_pos=p_faces)\n",
        "    # loss optimization\n",
        "    loss = debiasing_train_step(x, y)\n",
        "    \n",
        "    # plot the progress every 200 steps\n",
        "    if j % 500 == 0: \n",
        "      mdl.util.plot_sample(x, y, dbvae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgK77aB9oDtX"
      },
      "source": [
        "dbvae_logits = [dbvae.predict(np.array(x, dtype=np.float32)) for x in test_faces]\n",
        "dbvae_probs = tf.squeeze(tf.sigmoid(dbvae_logits))\n",
        "\n",
        "xx = np.arange(len(keys))\n",
        "plt.bar(xx, standard_classifier_probs.numpy().mean(1), width=0.2, label=\"Standard CNN\")\n",
        "plt.bar(xx+0.2, dbvae_probs.numpy().mean(1), width=0.2, label=\"DB-VAE\")\n",
        "plt.xticks(xx, keys); \n",
        "plt.title(\"Network predictions on test dataset\")\n",
        "plt.ylabel(\"Probability\"); plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\");\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}